{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import numbers\n",
    "url = 'http://www.seatexpert.com/'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'}\n",
    "result = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(result.text, \"html.parser\")\n",
    "UA_links=[]\n",
    "airlines=[]\n",
    "final_data=[]\n",
    "for m in soup.find_all(class_=\"heading\"):\n",
    "    airlines.append(m.get_text())\n",
    "for m in soup.find_all('a'):\n",
    "    if (m.get('href').find('/seatmap/') != -1):\n",
    "        UA_links.append('http://seatexpert.com'+m.get('href'))\n",
    "for link_2_process in UA_links:\n",
    "    result_link = requests.get(link_2_process, headers=headers)\n",
    "    soup_link = BeautifulSoup(result_link.text, \"html.parser\")\n",
    "    title = soup_link.select_one('title').text\n",
    "    for air in airlines:\n",
    "        if title.find(air) != -1:\n",
    "            airline = air\n",
    "            aircraft=title.replace(air,'').replace('- SeatExpert','')\n",
    "        seat = 0\n",
    "        data=[]\n",
    "        for m in soup_link.find_all(class_=\"row\"):\n",
    "            if m.get_text().isdigit():\n",
    "                seat = seat + int(m.get_text())\n",
    "        data.extend([airline,aircraft.strip(),seat])\n",
    "        final_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=['a',1,'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 1, 'b']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "with io.open('seatexpert.csv', 'w', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Airlines\", \"Aircraft\", \"Seats\"])\n",
    "    for data in final_data:\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adria Airways', 'Airbus A319', 135]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['British Airways', 'Boeing 767 (New Club World)', 192]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_link = requests.get('http://www.seatexpert.com//seatmap/92/British_Airways_Boeing_767_(New_Club_World)/', headers=headers)\n",
    "soup_link = BeautifulSoup(result_link.text, \"html.parser\")\n",
    "title = soup_link.select_one('title').text\n",
    "for air in airlines:\n",
    "    if title.find(air) != -1:\n",
    "        airline = air\n",
    "        aircraft=title.replace(air,'').replace('- SeatExpert','')\n",
    "seat = 0\n",
    "data=[]\n",
    "for m in soup_link.find_all(class_=\"row\"):\n",
    "    if m.get_text().isdigit():\n",
    "        seat = seat + int(m.get_text())\n",
    "data.extend([airline,aircraft.strip(),seat])\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for m in soup_link.find_all(class_=\"h1-fix\"):\n",
    "        final = m.get_text().split()[:3]\n",
    "    seat = 0\n",
    "    for m in soup_link.find_all(class_=\"value\"):\n",
    "        seat = seat + int(m.get_text().split(\" \")[0])\n",
    "    final.append(seat)\n",
    "    final_data.append(final)\n",
    "#print (final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
